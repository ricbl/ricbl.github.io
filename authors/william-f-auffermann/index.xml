<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>William F Auffermann | Ricardo Bigolin Lanfredi</title>
    <link>/authors/william-f-auffermann/</link>
      <atom:link href="/authors/william-f-auffermann/index.xml" rel="self" type="application/rss+xml" />
    <description>William F Auffermann</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 01 Apr 2020 16:50:07 -0600</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>William F Auffermann</title>
      <link>/authors/william-f-auffermann/</link>
    </image>
    
    <item>
      <title>Eye-tracking Annotations for Deep Learning Radiology Applications</title>
      <link>/project/eye/</link>
      <pubDate>Wed, 01 Apr 2020 16:50:07 -0600</pubDate>
      <guid>/project/eye/</guid>
      <description>&lt;div style=&#34;text-align: justify &#34;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; This project is NIH-funded, started in 2020, and aims to collect eye-tracking data as a non-intrusive way of providing localization information on labels associated with each chest x-ray. The data collection will include timestamped transcriptions of the dictations o radiological reports, making the association between region looked and word said at a given moment possible. The project&#39;s steps include: 
&lt;ul&gt;
    &lt;li&gt;providing all collected data as an open dataset,&lt;/li&gt;
    &lt;li&gt;evaluating interpretability methods for deep learning methods when compared to the attention from radiologists, and&lt;/li&gt;
    &lt;li&gt;using collected data as supervision for novel deep learning models.&lt;/li&gt;
&lt;/ul&gt;
&lt;a href=&#34;https://www.sci.utah.edu/eyetracking-cxr.html&#34;&gt;Project Homepage&lt;/a&gt;
 &lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
