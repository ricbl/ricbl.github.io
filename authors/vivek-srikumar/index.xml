<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vivek Srikumar | Ricardo Bigolin Lanfredi</title>
    <link>/authors/vivek-srikumar/</link>
      <atom:link href="/authors/vivek-srikumar/index.xml" rel="self" type="application/rss+xml" />
    <description>Vivek Srikumar</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 01 Apr 2020 16:50:07 -0600</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Vivek Srikumar</title>
      <link>/authors/vivek-srikumar/</link>
    </image>
    
    <item>
      <title>Eye-tracking Annotations for Deep Learning Radiology Applications</title>
      <link>/project/eye/</link>
      <pubDate>Wed, 01 Apr 2020 16:50:07 -0600</pubDate>
      <guid>/project/eye/</guid>
      <description>&lt;div style=&#34;text-align: justify &#34;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; This project is NIH-funded, starting in 2020, and aims to collect eye-tracking data as a non-intrusive way of providing localization information on labels associated with each x-ray. The data collection will include the audio recording of reports, making the association between region looked and word said at a given moment possible. The project&#39;s steps include: 
&lt;ul&gt;
    &lt;li&gt;analyzing the alignment between dictation / eye fixations / pupil dilation / bounding box annotations,&lt;/li&gt;
    &lt;li&gt;providing all collected data as an open dataset, and&lt;/li&gt;
    &lt;li&gt;using collected data as supervision for novel deep learning models.&lt;/li&gt;
&lt;/ul&gt;
 &lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>COPD from Chest X-rays</title>
      <link>/project/copd/</link>
      <pubDate>Mon, 21 Aug 2017 16:50:07 -0600</pubDate>
      <guid>/project/copd/</guid>
      <description>&lt;div style=&#34;text-align: justify &#34;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; After collecting a dataset of chest x-rays and pulmonary function tests of the same patient within six months of the x-ray, we performed several investigations in terms of automatic medical image assessment and the interpretability of associated models. These investigations include: 
&lt;ul&gt;
     &lt;li&gt; modeling the modifications caused by disease severity in the chest x-rays (&lt;a href=&#34;/publication/lanfredi-2019-adversarial/&#34;&gt;check here&lt;/a&gt;),&lt;/li&gt;
     &lt;li&gt; using deformation fields to model disease effect to find dataset biases (&lt;a href=&#34;/publication/lanfredi-2020-flow/&#34;&gt;check here&lt;/a&gt;),&lt;/li&gt;
     &lt;li&gt; proposing a mathematical formulation to associate interpretability alignment with adversarial robustness (still unpublished), and &lt;/li&gt;
     &lt;li&gt; showing that the chest x-rays provide more information about COPD diagnosis than radiologist reports (still unpublished).&lt;/li&gt;
 &lt;/ul&gt;
 &lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
